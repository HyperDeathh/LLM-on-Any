[
  {
    "id": "llama-3.1-8b-q4",
    "name": "Llama 3.1 8B Instruct Q4_0",
    "size": "~4.5 GB",
    "family": "llama",
    "format": "gguf",
    "url": "https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q4_0.gguf?download=true",
    "sha256": null
  },
  {
    "id": "qwen2-1.5b-instruct-q4_0",
    "name": "Qwen2 1.5B Instruct Q4_0",
    "size": "~2.3 GB",
    "family": "qwen",
    "format": "gguf",
    "url": "https://huggingface.co/Qwen/Qwen2-1.5B-Instruct-GGUF/resolve/main/qwen2-1_5b-instruct-q4_0.gguf?download=true"
  },
  {
    "id": "tinyllama-1.1b-chat",
    "name": "TinyLlama 1.1B Chat v1.0",
    "size": "~2.0 GB",
    "family": "tinyllama",
    "format": "safetensors",
    "url": "",
    "hf_repo": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "hf_filename": null,
    "gated": false
  },
  {
    "id": "gpt-oss-20b",
    "name": "GPT-OSS 20B (original, multi-file)",
    "size": "varies",
    "family": "gpt-oss",
    "format": "safetensors",
    "url": "",
    "hf_repo": "openai/gpt-oss-20b",
    "hf_filename": null,
    "gated": false
  },
  {
    "id": "gpt-oss-120b",
    "name": "GPT-OSS 120B (original, multi-file)",
    "size": ">100 GB",
    "family": "gpt-oss",
    "format": "safetensors",
    "url": "",
    "hf_repo": "openai/gpt-oss-120b",
    "hf_filename": null,
    "gated": false
  }
]
