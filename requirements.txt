# Core dependencies for LLM-on-Any (mirrors pyproject.toml)
requests>=2.31.0
tqdm>=4.66.0
typer>=0.12.0
rich>=13.7.0
# Pin to <0.33 to avoid hf-xet (Rust/maturin) on Termux/Android
huggingface_hub>=0.21.4,<0.33
llama-cpp-python>=0.2.90
transformers>=4.41.0
accelerate>=0.30.0
# --- Optional extras (uncomment as needed) ---
# GGUF backend (llama.cpp bindings)
# llama-cpp-python>=0.2.90
#
# Transformers backend (safetensors)
# transformers>=4.41.0
# accelerate>=0.30.0
# PyTorch is platform-specific; install a matching build, e.g. CPU wheels:
# pip install torch --index-url https://download.pytorch.org/whl/cpu
